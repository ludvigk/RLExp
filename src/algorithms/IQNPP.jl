export IQNPPLearner, ImplicitQuantileNetPP

using Functors: @functor
using Flux: params, unsqueeze
using Random: AbstractRNG, GLOBAL_RNG
using StatsBase: mean
using Zygote: gradient
using ChainRulesCore: ignore_derivatives
using RLExp

"""
    ImplicitQuantileNet(;Ïˆ, Ï•, header)
```
        quantiles (n_action, n_quantiles, batch_size)
           â†‘
         header
           â†‘
feature â†±  â¨€   â†° transformed embedding
       Ïˆ       Ï•
       â†‘       â†‘
       s        Ï„
```
"""
Base.@kwdef struct ImplicitQuantileNetPP{A,B,C}
    Ïˆ::A
    Ï•::B
    header::C
end

@functor ImplicitQuantileNetPP

function (net::ImplicitQuantileNetPP)(s, emb)
    features = net.Ïˆ(s)  # (n_feature, batch_size)
    emb_aligned = net.Ï•(emb)  # (n_feature, N * batch_size)
    merged = unsqueeze(features, dims=2) .* reshape(emb_aligned, size(features, 1), :, size(features, 2))  # (n_feature, N, batch_size)
    quantiles = net.header(reshape(merged, size(merged)[1:end-2]..., :)) # flattern last two dimension first
    reshape(quantiles, :, size(merged, 2), size(merged, 3))  # (n_action, N, batch_size)
end

Base.@kwdef mutable struct IQNPPLearner{A<:Approximator{<:TwinNetwork}} <: AbstractLearner
    approximator::A
    Î³::Float32 = 0.99f0
    Îº::Float32 = 1.0f0
    N::Int = 32
    Nâ€²::Int = 32
    Nâ‚‘â‚˜::Int = 64
    K::Int = 32
    rng::AbstractRNG = GLOBAL_RNG
    device_rng::AbstractRNG = rng
    # for logging
    loss::Float32 = 0.0f0
    logging_params = DefaultDict(0.0)
end

@functor IQNPPLearner (approximator, device_rng)

embed(x, Nâ‚‘â‚˜) = cos.(Float32(Ï€) .* (1:Nâ‚‘â‚˜) .* reshape(x, 1, :))

# the last dimension is batch_size
function (learner::IQNPPLearner)(s::AbstractArray)
    batch_size = size(s)[end]
    Ï„ = rand(learner.device_rng, Float32, learner.K, batch_size)

    Ï„â‚‘â‚˜ = embed(Ï„, learner.Nâ‚‘â‚˜)
    quantiles = learner.approximator(s, Ï„â‚‘â‚˜)
    dropdims(mean(quantiles; dims=2); dims=2)
end

function (L::IQNPPLearner)(env::AbstractEnv)
    s = env |> state |> send_to_device(L)
    q = s |> unsqueeze(dims=ndims(s) + 1) |> L |> vec
    q |> send_to_host
end

function huber_norm(td, Îº)
    abs_error = abs.(td)
    quadratic = min.(abs_error, Îº)
    linear = abs_error .- quadratic
    return 0.5f0 .* quadratic .* quadratic .+ Îº .* linear
end

function l2_norm(td, Îº)
    return td .^ 2
end

function l1_norm(td, Îº)
    return td .^ 2
end

function energy_distance(x, y; Îº=1.0f0)
    n = size(x, 2)
    m = size(y, 2)

    x_ = Flux.unsqueeze(x, dims=2)
    _x = Flux.unsqueeze(x, dims=3)
    _y = Flux.unsqueeze(y, dims=3)
    d_xy = dropdims(sum(l1_norm(x_ .- _y, Îº), dims=(2, 3)), dims=(2, 3))
    d_xx = dropdims(sum(l1_norm(x_ .- _x, Îº), dims=(2, 3)), dims=(2, 3))
    Îµ = 2 / (n * m) .* d_xy .- 1 / n^2 .* d_xx
    return Îµ
end

# function energy_distance_fast(x, y; Îº=1.0f0)
#     n = size(x, 2)
#     m = size(y, 2)

#     x_ = permutedims(x, (2, 1, 3))
#     y_ = permutedims(y, (2, 1, 3))
#     x_ = Flux.unsqueeze(x, dims=1)
#     _x = Flux.unsqueeze(x, dims=2)
#     _y = Flux.unsqueeze(y, dims=2)
#     # d_xy = dropdims(sum(l2_norm(x_ .- _y, Îº), dims=(2, 3)), dims=(2, 3))
#     # d_xx = dropdims(sum(l2_norm(x_ .- _x, Îº), dims=(2, 3)), dims=(2, 3))
#     Îµ = dropdims(batched_mul(x_, _x)) + 2batched_mul(x_, _y)
#     # Îµ = 2 / (n * m) .* d_xy .- 1 / n^2 .* d_xx
#     return Îµ
# end

function RLBase.optimise!(learner::IQNPPLearner, batch::NamedTuple)
    A = learner.approximator
    Z = A.model.source
    Zâ‚œ = A.model.target
    N = learner.N
    Nâ€² = learner.Nâ€²
    Nâ‚‘â‚˜ = learner.Nâ‚‘â‚˜
    Îº = learner.Îº
    D = device(Z)
    # s, sâ€², a, r, t = map(x -> batch[x], SSâ€²ART)
    s = send_to_device(D, collect(batch.state))
    r = send_to_device(D, batch.reward)
    t = send_to_device(D, batch.terminal)
    sâ€² = send_to_device(D, collect(batch.next_state))
    a = send_to_device(D, batch.action)


    batch_size = length(t)
    Ï„â€² = rand(learner.device_rng, Float32, Nâ€², batch_size)  # TODO: support Î² distribution
    Ï„â‚‘â‚˜â€² = embed(Ï„â€², Nâ‚‘â‚˜)
    zâ‚œ = Zâ‚œ(sâ€², Ï„â‚‘â‚˜â€²)
    avg_zâ‚œ = mean(zâ‚œ, dims=2)

    if haskey(batch, :next_legal_actions_mask)
        masked_value = similar(batch.next_legal_actions_mask, Float32)
        masked_value = fill!(masked_value, typemin(Float32))
        masked_value[batch.next_legal_actions_mask] .= 0
        avg_zâ‚œ .+= masked_value
    end

    aâ‚œ = argmax(avg_zâ‚œ, dims=1)
    aâ‚œ = aâ‚œ .+ typeof(aâ‚œ)(CartesianIndices((0:0, 0:Nâ€²-1, 0:0)))
    qâ‚œ = reshape(zâ‚œ[aâ‚œ], :, batch_size)
    target = reshape(r, 1, batch_size) .+ learner.Î³ * reshape(1 .- t, 1, batch_size) .* qâ‚œ  # reshape to allow broadcast

    Ï„ = rand(learner.device_rng, Float32, N, batch_size)
    Ï„â‚‘â‚˜ = embed(Ï„, Nâ‚‘â‚˜)
    a = CartesianIndex.(repeat(a, inner=N), 1:(N*batch_size))

    gs = gradient(params(A)) do
        z_raw = Z(s, Ï„â‚‘â‚˜)
        z = reshape(z_raw, size(z_raw)[1:end-2]..., :)
        q = z[a]

        # TD_error = reshape(target, Nâ€², 1, batch_size) .- reshape(q, 1, N, batch_size)
        # can't apply huber_loss in RLCore directly here
        # abs_error = abs.(TD_error)
        # quadratic = min.(abs_error, Îº)
        # linear = abs_error .- quadratic
        # huber_loss = 0.5f0 .* quadratic .* quadratic .+ Îº .* linear

        # # dropgrad
        # raw_loss =
        #     abs.(reshape(Ï„, 1, N, batch_size) .- ignore_derivatives(TD_error .< 0)) .*
        #     huber_loss ./ Îº
        # loss_per_quantile = reshape(sum(raw_loss; dims=1), N, batch_size)
        # loss_per_element = mean(loss_per_quantile; dims=1)  # use as priorities

        # @show size(q)
        # @show size(target)
        target = reshape(target, 1, Nâ€², batch_size)
        q = reshape(q, 1, N, batch_size)
        loss = mean(energy_distance(q, target))
        ignore_derivatives() do
            learner.loss = loss
            learner.logging_params["ð¿"] = loss
        end
        loss
    end

    optimise!(A, gs)
end